---
title: "PEC03"
author: "Angel A. Urbina & Almudena Caballero Manzanas"
date: '`r format(Sys.Date(),"%e de %B %Y")`'
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 2
  pdf_document: default
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.width=8, fig.height=4) 

```

### Carga de Librerias

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Carga y chequeo de Datos

# Carga paquetes
library('ggplot2')
library('scales') # visualización
library('dplyr') # manipulación datos
library('kableExtra') # Visualización de Datos
library(data.table)
library(stringr)
#library(DT)
library(tidyr)
library(corrplot)
#library(leaflet)
library(lubridate)
```

### Descarga datos desde GitHub

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Directorio de trabajo actual
Directorio <- getwd()

# Lectura de Datos
library(readr)
heart<-read.csv("https://raw.githubusercontent.com/UOCACM/PAC2/main/DATASET/heart.csv")

# Visualización Datos descargados
kable(head(heart, 3)) %>% 
  kable_styling(full_width = FALSE)
```

# Práctica 2 (25% nota final)

## Presentación

En esta práctica se elabora un caso práctico orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas.

Para hacer esta práctica tendréis que trabajar en grupos de 2 personas. Tendréis que entregar un solo archivo con el enlace al repositorio Git donde se encuentren las soluciones, incluyendo los nombres de los componentes del equipo. Podéis utilizar la Wiki de Github para describir vuestro equipo y los diferentes archivos que corresponden a vuestra entrega. Cada miembro del equipo tendrá que contribuir con su usuario Github.

Aunque no se trata del mismo enunciado ni de soluciones que obtuvieron la máxima nota, los siguientes ejemplos de ediciones anteriores os pueden servir como guía:

- Ejemplo: https://github.com/Bengis/nba-gap-cleaning

- Ejemplo complejo (archivo adjunto).

Además, se debe entregar un vídeo explicativo de la práctica, donde ambos integrantes del equipo expliquen con sus propias palabras el desarrollo de la práctica, basándose en las preguntas del enunciado para justificar y explicar el código desarrollado. Este vídeo se deberá entregar a través de un enlace a Google Drive que se deberá proporcionar junto con enlace al repositorio Git.

## Competencias

En esta práctica se desarrollan las siguientes competencias del Máster de Data Science:

- Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.

- Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis.

## Objetivos

Los objetivos concretos de esta práctica son:

- Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.

- Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico.

- Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.

- Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.

- Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.

- Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.

- Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos.

## Descripción de la Práctica a realizar

El objetivo de esta actividad será el tratamiento de un dataset, que puede ser el creado en la práctica 1 o bien cualquier dataset libre disponible en Kaggle (https://www.kaggle.com).

Algunos ejemplos de dataset con los que podéis trabajar son:

- Red Wine Quality (https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009)

- Titanic: Machine Learning from Disaster (https://www.kaggle.com/c/titanic)

El último ejemplo corresponde a una competición activa de Kaggle de manera que, opcionalmente, podéis aprovechar el trabajo realizado durante la práctica para entrar en esta competición.

Importante: si se elige un dataset diferente de los propuestos es importante que este contenga una amplia variedad de datos numéricos y categóricos para poder realizar un análisis más rico y poder responder a las diferentes preguntas planteadas en el enunciado de la práctica.

Siguiendo las principales etapas de un proyecto analítico, las diferentes tareas a realizar (y justificar) son las siguientes:

# 1. Descripción del dataset. (Puntuación 0.5 ptos)

Verificamos la estructura del juego de datos principal. Vemos el número de columnas que tenemos y ejemplos de los contenidos de las filas.
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Estructura de los datos
structure <- str(heart)
```
### Tipos de Datos

```{r echo=TRUE, message=FALSE, warning=FALSE}
sapply(heart, class)
```


### Tamaño Datos
```{r, eval=TRUE,echo=TRUE}
dim(heart)
```

**Resumen Datos**

Nuestro DataSet esta originalmente en:

https://www.kaggle.com/datasets/zhaoyingzhu/heartcsv

Son de caracter publico

Vemos que tenemos **14** variables y **303** registros

Revisamos la descripción de las variables contenidas en el fichero y si los tipos de variables se corresponden con las que hemos cargado. Las organizamos lógicamente para darles sentido y construimos un pequeño diccionario de datos utilizando la documentación auxiliar.

+ **age**  col_double(),                          [Edad Paciente]
+ **sex** col_double(),                           [Sexo Paciente]
                                                      0 = female
                                                      1 = male
+ **cp** col_double(),                            [Tipo de Dolor de Pecho]
                                                      1='typical angina'
                                                      2 = 'atypical angina'
                                                      3 = 'non-anginal pain'
                                                      4 = 'asymptomatic'
+ **trestbps** col_double(),                      [resting_blood_pressure]
+ **chol** col_double(),                          [cholesterol]
+ **fbs** col_double(),                           [fasting_blood_sugar]
                                                      0='lower than 120mg/ml'
                                                      1='greater than 120mg/ml'
+ **restecg** col_double(),                       [rest_ecg]
                                                      0 ='normal'
                                                      1 ='ST-T wave abnormality'
                                                      2 ='left ventiricular hypertrophy'
+ **thalach** col_double(),                       [max_heart_rate_achieved]
+ **exang** col_double(),                         [exercise_induced_angina]
                                                      0 = 'no'
                                                      1 = 'yes'
+ **oldpeak**  col_double(),                      [st_depression]
+ **slope**  col_double(),                        [st_slope]
                                                      1 = 'upsloping'
                                                      2 = 'flat'
                                                      3 = 'downsloping'
+ **ca** col_double(),                            [num_major_vessels]
+ **thal**  col_double(),                         [thalassemia]
                                                      1 = 'normal'
                                                      2 = 'fixed defect'
                                                      3 = 'reversable defect'
+ **target**  col_double()                        [target]
                                                      Yes
                                                      No

**Resumen DataSet**

+ **Numero de variables** 	15
+ **Numero de observaciones** 	303
+ **Celdas perdidas** 	6 (0.1%)
+ **Filas duplicadas**  0 (0.0%)

## 1.1.¿Por qué es importante y qué pregunta/problema pretende responder?

Este Data set recopila un conjunto de datos clinicos cuyo objetivo es permitir intentar identificar posibles factores que a fectan a la presencia de infartos en personas.

Es importante ya que se trata de un conjunto de datos reales que nos permitir construir modelos para la predicción de este tipo de situaciones que son una de las causas mas frecuentes de fallecimientos en las personas.

# 2. Integración y selección de los datos de interés a analizar. (Puntuación 0.5 ptos)

### Puede ser el resultado de adicionar diferentes datasets o una subselección útil de los datos originales, en base al objetivo que se quiera conseguir.

Procedemos a construir vectores que nos permitan mejorar la identificación de las variables

```{r echo=TRUE, message=FALSE, warning=FALSE}
sex <- c('female',
         'male')
cp <- c('typical angina',
         'atypical angina',
         'non-anginal pain',
         'asymptomatic')
fbs <- c('lower than 120mg/ml',
         'greater than 120mg/ml')
rest_ecg <- c( 'normal',
               'ST-T wave abnormality',
               'left ventiricular hypertrophy')
exercise_induced_angina <- c( 'yes',
                              'no')
st_slope <- c('upsloping',
              'flat',
              'downsloping')
thalassemia <- c('normal',
                 'fixed defect',
                 'reversable defect')
infarto <- c('Yes',
             'No')
```

### Construcción Dataset Factorizado
```{r, eval=TRUE,echo=TRUE}


# Cambio valores
Datos <- heart %>%
    mutate(sex = case_when(sex == 0 ~ 'female',
                           sex == 1  ~ 'male'),
          cp = case_when(cp == 1 ~ 'typical angina',
                          cp == 2 ~ 'atypical angina',
                          cp == 3 ~ 'non-anginal pain',
                          cp == 4 ~ 'asymptomatic'
                          ),
         fbs = case_when(fbs == 0 ~ 'lower than 120mg/ml',
                           fbs == 1 ~ 'greater than 120mg/ml'
                          ),
         restecg = case_when(restecg == 0 ~ 'normal',   
                               restecg == 1 ~ 'ST-T wave abnormality', 
                               restecg == 2 ~ 'left ventiricular hypertrophy'
           ),
         exang = case_when(exang == 0 ~ 'no',
                             exang == 1 ~ 'yes'
                          ),
         slope = case_when(slope == 0 ~ 'upsloping',
                              slope == 1 ~ 'flat',
                              slope == 2 ~ 'downsloping'
                          ),
        thal = case_when(thal == 1 ~ 'normal',
                            thal == 2 ~ 'fixed defect',                           
                            thal == 3 ~ 'reversable defect'
                          ))
           

# Factorización
Datos <- Datos %>%
  mutate(sex = relevel(as.factor(sex), 'female', 'male'),
         cp = relevel(as.factor(cp), 'typical angina', 'atypical angina', 'non-anginal pain', 'asymptomatic'),
         fbs = relevel(as.factor(fbs), 'lower than 120mg/ml', 'greater than 120mg/ml'),
         restecg = relevel(as.factor(restecg), 'normal', 'ST-T wave abnormality', 'left ventiricular hypertrophy'),
         exang = relevel(as.factor(exang), 'no', 'yes'),
         slope = relevel(as.factor(slope), 'upsloping', 'flat', 'downsloping'),
         thal = relevel(as.factor(thal), 'normal', 'fixed defect', 'reversable defect'
         )
  )
```


# 3. Limpieza de los datos. (Puntuación 2 ptos)

## 3.1. ¿Los datos contienen ceros o elementos vacíos?

### Comprobacion presencia de NA
```{r, eval=TRUE,echo=TRUE}
datosNA <- colSums(is.na(heart))
print(datosNA)
```

No hay valores NA

### Tabla resumen Valores perdidos
```{r echo=TRUE, message=FALSE, warning=FALSE}
missing_values <- heart %>% summarize_each(funs(sum(is.na(.))/n()))

missing_values <- gather(missing_values, key="caracteristica", value="Perdidos")
missing_values %>% 
  ggplot(aes(x=reorder(caracteristica,-Perdidos),y=Perdidos)) +
  geom_bar(stat="identity",fill="red")+
  coord_flip()+theme_bw()
```

No hay valores perdidos

### Gestiona cada uno de estos casos.

Se trata de una fuente de datos que no contiene valores NA ni valores perdidos ya que procede de datos de una investigacion clinica. ( Asumimos que por tanto que a los valores publicados Kaggle que hemos cogido ya se han realizado los pasos indicados de limpieza)

## 3.2. Identifica y gestiona los valores extremos.

```{r echo=TRUE, message=FALSE, warning=FALSE}

g_caja<-boxplot(heart, col="skyblue", frame.plot=F)

```

# 4. Análisis de los datos. (Puntuación 2.5 ptos)

## 4.1. Selección de los grupos de datos que se quieren analizar/comparar 
(p. e., si se van a comparar grupos de datos, ¿cuáles son estos grupos y qué tipo de análisis se van a aplicar?)

```{r echo=TRUE, message=FALSE, warning=FALSE}

```

## 4.2. Comprobación de la normalidad y homogeneidad de la varianza.

```{r echo=TRUE, message=FALSE, warning=FALSE}

```

## 4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.

```{r echo=TRUE, message=FALSE, warning=FALSE}

```

# 5 Representación de los resultados a partir de tablas y gráficas. (Puntuación 2 ptos) Este apartado se puede responder a lo largo de la práctica, sin necesidad de concentrar todas las representaciones en este punto de la práctica.

```{r echo=TRUE, message=FALSE, warning=FALSE}

```

# 6 Resolución del problema. (Puntuación 0.5 ptos) A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?

```{r echo=TRUE, message=FALSE, warning=FALSE}

```

# 7 Código: (Puntuación 2 ptos) Hay que adjuntar el código, preferiblemente en R, con el que se ha realizado la limpieza, análisis y representación de los datos.
Si lo preferís, también podéis trabajar en Python.

```{r echo=TRUE, message=FALSE, warning=FALSE}

```

### Ejemplo codigo Código que puede servir de referencia https://www.kaggle.com/code/rtatman/getting-started-in-r-load-data-into-r



```{r echo=TRUE, message=FALSE, warning=FALSE}

```

```{r echo=TRUE, message=FALSE, warning=FALSE}

```

```{r echo=TRUE, message=FALSE, warning=FALSE}

```

```{r echo=TRUE, message=FALSE, warning=FALSE}

```


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
